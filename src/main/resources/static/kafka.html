<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Apache Kafka Overview</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            line-height: 1.6;
            max-width: 800px;
            margin: 20px auto;
            padding: 20px;
            background-color: #f9f9f9;
            border: 1px solid #ddd;
        }
        h1, h2 {
            color: #333;
        }
        pre {
            background-color: #f4f4f4;
            padding: 10px;
            border-left: 4px solid #ccc;
            overflow-x: auto;
        }
        .diagram {
            font-family: monospace;
            background-color: #f4f4f4;
            padding: 10px;
            margin: 20px 0;
            white-space: pre;
            border-left: 4px solid #ccc;
        }
    </style>
</head>
<body>

<h1>Apache Kafka Overview</h1>

<p>Apache Kafka is a distributed event streaming platform that enables high throughput, low-latency data pipelines and real-time processing. It is designed for fault tolerance and horizontal scalability. Below are its key components and architecture.</p>

<h2>Key Components of Apache Kafka:</h2>
<ul>
    <li><strong>Producers</strong>: Applications that publish (write) data (messages) to Kafka topics.</li>
    <li><strong>Consumers</strong>: Applications that subscribe to (read) data from Kafka topics.</li>
    <li><strong>Brokers</strong>: Kafka servers that receive data from producers, store it, and serve it to consumers.</li>
    <li><strong>Topics</strong>: Categories or streams where messages are published. Kafka stores messages in topics, which are further divided into partitions.</li>
    <li><strong>Partitions</strong>: A single topic can be divided into multiple partitions to enable parallel processing.</li>
    <li><strong>Zookeeper</strong>: A service that manages the Kafka cluster, keeping track of brokers and coordinating distributed processes.</li>
</ul>

<h2>Kafka Architecture Diagram</h2>
<div class="diagram">
    +-----------------------+<br>
    |                       |<br>
    |       Zookeeper        |<br>
    |                       |<br>
    +-----------------------+<br>
    ^<br>
    |<br>
    +-----------------------+<br>
    |     Kafka Broker       |<br>
    +-----------------------+<br>
    | Topic A | Topic B      |<br>
    |-------- |------------  |<br>
    | Part 0  | Part 0        |<br>
    | Part 1  | Part 1        |<br>
    | Part 2  | Part 2        |<br>
    +-----------------------+<br>
    ^     ^     ^     ^<br>
    |     |     |     |<br>
    +------------+     +------------+<br>
    | Producer 1 |     | Producer 2 |<br>
    +------------+     +------------+<br>
    |                    |<br>
    v                    v<br>
    +-------------------------------+<br>
    | Kafka Topics (Stream of Events)|<br>
    +-------------------------------+<br>
    ^<br>
    |<br>
    +---------------------------+<br>
    | Consumer Group 1           |<br>
    +---------------------------+<br>
    | Consumer 1 | Consumer 2    |<br>
    +---------------------------+<br>
</div>

<h2>Detailed Explanation of Kafka Components:</h2>

<h3>1. Kafka Topic</h3>
<p>A Kafka <strong>topic</strong> is a logical channel where producers write and consumers read messages. Topics are divided into <strong>partitions</strong> for parallelism and scalability.</p>

<h3>2. Partitions</h3>
<p><strong>Partitions</strong> allow Kafka to parallelize the data. Each partition has an offset to keep track of messages. Partitions are replicated across brokers for fault tolerance.</p>

<h3>3. Producers</h3>
<p><strong>Producers</strong> publish data to Kafka topics. They can decide which partition to send the message to and can handle messages asynchronously for high throughput.</p>

<h3>4. Consumers</h3>
<p><strong>Consumers</strong> subscribe to topics and read data from Kafka. They keep track of the offset to know which messages have been processed.</p>
<p>Consumers can be grouped into a <strong>consumer group</strong> where each consumer reads from a separate partition for parallelism.</p>

<h3>5. Kafka Broker</h3>
<p>A <strong>Kafka Broker</strong> handles the storage and retrieval of messages. It coordinates data replication and processes requests for topics and partitions.</p>

<h3>6. Zookeeper</h3>
<p><strong>Zookeeper</strong> manages the Kafka cluster, tracks brokers, and helps in partition leader election and coordination of tasks.</p>

<h2>Kafka Workflow:</h2>
<ul>
    <li><strong>Producers write to topics</strong>: Producers send messages to specific Kafka topics, which are divided into partitions.</li>
    <li><strong>Brokers store data</strong>: Kafka brokers store messages and replicate them for fault tolerance.</li>
    <li><strong>Consumers read messages</strong>: Consumers subscribe to topics and read messages from the partitions. They keep track of their offsets to ensure no duplication.</li>
    <li><strong>Consumer Groups</strong>: Multiple consumers in a group ensure parallel consumption of messages from different partitions.</li>
</ul>

<h2>Fault Tolerance and High Availability</h2>
<p>Kafka is designed for <strong>fault tolerance</strong> through replication. If a broker fails, another broker takes over its partitions. Kafka also ensures <strong>high availability</strong> using Zookeeper to coordinate leader election and manage the cluster state.</p>

<h2>Use Cases</h2>
<ul>
    <li>Real-time analytics</li>
    <li>Event sourcing</li>
    <li>Log aggregation</li>
</ul>

</body>
</html>
